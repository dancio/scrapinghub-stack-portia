#!/usr/bin/env python
import os
import sys
import json
import shutil
import requests
from retrying import retry
from itertools import count
from urlparse import urljoin
from urllib import urlencode
from cStringIO import StringIO
from sh_scrapy.env import decode_uri

BUNDLE_DIR = '/scrapy'
BUNDLE_PATH = os.path.join(BUNDLE_DIR, 'project-slybot.zip')
BUNDLE_URL = '/api/projects/{project}/download/{spider}/'

DOWNLOAD_RETRY_EXCEPTIONS = (
    requests.exceptions.Timeout,
    requests.exceptions.ConnectionError,
    requests.exceptions.HTTPError,
)


def prepare_portia_bundle():
    """ Download Portia bundle to project directory """
    portia_url, jobauth, spider_id, version, branch = extract_job_data()
    jobkey = os.environ['SHUB_JOBKEY']
    project_id = jobkey.split('/')[0]

    bundle_url = BUNDLE_URL.format(project=project_id, spider=spider_id)
    bundle_full_url = urljoin(portia_url, bundle_url).strip('/')
    args = {k: v for k, v in [('version', version), ('branch', branch)] if v}
    if args:
        bundle_full_url = '%s?%s' % (bundle_full_url, urlencode(args))
    bundle_data = download_portia_bundle(bundle_full_url, jobkey, jobauth)

    with open(BUNDLE_PATH, 'wb') as outfile:
        shutil.copyfileobj(StringIO(bundle_data), outfile)


def extract_job_data():
    """Extract Portia-related data from JOB_DATA env variable."""
    job_data = decode_uri(envvar='JOB_DATA')
    keys = ('portia_url', 'auth', 'spider', 'version', 'branch')
    return [job_data.get(k, None) for k in keys]


def _retry_on_requests_error(exception):
    return isinstance(exception, DOWNLOAD_RETRY_EXCEPTIONS)


def backoffretry_delays(maxwait=3600, maxdelay=600, mindelay=0):
    w, delays = 0, []
    for x in count():
        s = max(min(x ** 2, maxdelay), mindelay)
        w += s
        if w > maxwait:
            break
        delays.append(s)
    return delays

delays = backoffretry_delays(maxwait=1200, mindelay=60)


@retry(retry_on_exception=_retry_on_requests_error,
       wait_func=lambda n, _: delays[n],
       stop_func=lambda n, _: len(delays) <= n + 1)
def download_portia_bundle(bundle_url, jobkey, jobauth):
    """Download Portia bundle from API using Bearer auth."""
    headers = {"Authorization": "Bearer {}".format(jobauth),
               "X-Job-Id": jobkey}
    bundle_req = requests.get(
        url=bundle_url,
        headers=headers,
        stream=True,
        timeout=300,
    )
    bundle_req.raise_for_status()
    return bundle_req.content


def update_environment_for_portia():
    """Modify current environment for Portia."""
    env = os.environ.copy()
    env['PROJECT_ZIPFILE'] = BUNDLE_PATH
    env['PROJECT_DIR'] = BUNDLE_DIR
    env['SHUB_HS_USER_AGENT'] = 'portia-stack'
    return env


def _print_flush(s):
    """Debug helper to track entrypoints execution"""
    print("portia-entrypoint: " + s)
    sys.stdout.flush()


def main():
    _print_flush("entered")
    prepare_portia_bundle()
    env = update_environment_for_portia()
    _print_flush("exec env: %s" % env)
    if len(sys.argv) > 1:
        os.execvpe(sys.argv[1], sys.argv[1:], env)
    else:
        os.execvpe('/bin/bash', ['bash'], env)


if __name__ == '__main__':
    sys.exit(main())
